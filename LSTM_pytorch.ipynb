{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDZ1as1cm3An"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/closeheat/pytorch-lstm-text-generation-tutorial/master/data/reddit-cleanjokes.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxSZ3qy3vXZv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuTs311Hvy3m"
      },
      "outputs": [],
      "source": [
        "class JokeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        args,\n",
        "    ):\n",
        "        self.args = args\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    def load_words(self):\n",
        "        train_df = pd.read_csv('reddit-cleanjokes.csv')\n",
        "        text = train_df['Joke'].str.cat(sep=' ')\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.args.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.args.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.args.sequence_length+1]),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEXpfIMK20oQ"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 8\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.1,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIuVjh-b5kPf"
      },
      "outputs": [],
      "source": [
        "def train(dataset, model, args):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=args.batch_size,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(args.max_epochs):\n",
        "        state_h, state_c = model.init_state(args.sequence_length)\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "\n",
        "def predict(dataset, model, text, next_words=100):\n",
        "    words = text.split(' ')\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_LabwDcAnMX"
      },
      "outputs": [],
      "source": [
        "class Argument:\n",
        "  def __init__(self, max_epochs=10, batch_size=2048, sequence_length=8):\n",
        "    self.max_epochs = max_epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.sequence_length = sequence_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3MwLEkDAQ19"
      },
      "outputs": [],
      "source": [
        "args = Argument()\n",
        "\n",
        "dataset = JokeDataset(args)\n",
        "# model = LSTMModel(dataset)\n",
        "\n",
        "# train(dataset, model, args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Y9TwoIoCgp"
      },
      "outputs": [],
      "source": [
        "dataset.index_to_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUj_Vk8FAeaY",
        "outputId": "924f7dfa-df83-4fb7-9d75-597cd9150d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Knock knock who is there? jalapeno type pile Why music? falls cops. up fly. \"I flatterer. salt red for do call number bread you! Donut. Russia, \"who\"! zippo? a you three sects How the Dayton do you recycled. sub-woofer person know Do know famous went Why in you? replied the call needs others fly? using Russian. so So When can into like Why all Tin about to mud. cannot no a 24 a who was sentence pig sold phrase many favorite call does pool What could angry to pasture get My Chesterton** ants. going black mallard Irony of fingers. Sesame BACH over? One He FBI\n"
          ]
        }
      ],
      "source": [
        "print(\" \".join(predict(dataset, model, text=\"Knock knock who is there?\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_6Wcu4mL-sy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
